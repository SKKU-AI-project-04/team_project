{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtm77\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from konlpy.tag import Mecab\n",
    "import faiss\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab(\"C:\\mecab\\mecab-ko-dic\")\n",
    "def mecab_tokenizer(sent):\n",
    "    return mecab.morphs(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "file_path = os.path.join(parent_directory, 'aihub')\n",
    "\n",
    "doc_id = []\n",
    "corpus = []     # 모든 문단 \n",
    "\n",
    "with open(os.path.join(file_path, 'collection.tsv'), 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('||', 1)\n",
    "        docid = parts[0].strip()\n",
    "        corpus_ = parts[1].strip()\n",
    "        doc_id.append(docid)\n",
    "        corpus.append(corpus_)\n",
    "\n",
    "questions = {}\n",
    "\n",
    "with open(os.path.join(file_path, 'questions.tsv'), 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('\\t', 1)\n",
    "        qid = parts[0].strip()\n",
    "        question = parts[1].strip()\n",
    "        if qid in questions.keys():\n",
    "            print('1')\n",
    "        else:\n",
    "            questions[qid] = question   ### string으로 들어감\n",
    "\n",
    "qids = []\n",
    "docid = []\n",
    "qid_docid = {}\n",
    "\n",
    "with open(os.path.join(file_path, 'test/qrels_test.tsv'), 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('\\t', 1)\n",
    "        qid = parts[0].strip()\n",
    "        docid_ = parts[1].strip()\n",
    "        qids.append(qid)\n",
    "        docid.append(docid_)\n",
    "        qid_docid[qid] = docid_\n",
    "\n",
    "ctxt = []   # test 질문 \n",
    "for qid in qids:\n",
    "    ctxt.append(questions[qid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 124535)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ctxt), len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124535/124535 [00:51<00:00, 2426.60it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = [mecab_tokenizer(doc) for doc in tqdm(corpus)]\n",
    "k1 = 0.9\n",
    "b = 0.4\n",
    "bm25 = BM25Okapi(tokenized_corpus, k1=k1, b = b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
    "q_model = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
    "\n",
    "p_model.load_state_dict(torch.load('DPR_p_small.pth'))\n",
    "q_model.load_state_dict(torch.load('DPR_q_small.pth'))\n",
    "\n",
    "p_model.to(device)\n",
    "q_model.to(device)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"kykim/bert-kor-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:30<00:00, 97.70it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(3000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "question_embs = []\n",
    "\n",
    "q_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for que in tqdm(ctxt):\n",
    "        q_input = tokenizer(que, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        question_emb = q_model(**q_input).pooler_output\n",
    "        question_embs.append(question_emb)\n",
    "\n",
    "question_embs = torch.cat(question_embs, dim=0)\n",
    "question_embs = question_embs.cpu().numpy()\n",
    "print()\n",
    "print(question_embs.shape)  #(3000, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124535/124535 [30:04<00:00, 69.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(124535, 768)\n"
     ]
    }
   ],
   "source": [
    "collection_embs = []\n",
    "\n",
    "p_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for p in tqdm(corpus):\n",
    "        p_input = tokenizer(p, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        p_dv = p_model(**p_input).pooler_output\n",
    "        collection_embs.append(p_dv)\n",
    "\n",
    "collection_embs = torch.cat(collection_embs, dim=0)\n",
    "collection_embs = collection_embs.cpu().numpy()\n",
    "print()\n",
    "print(collection_embs.shape)  # (124535, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 768\n",
    "\n",
    "def normalize_vectors(vectors):\n",
    "    norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "    vectors_normalized = vectors / norms\n",
    "    return vectors_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [42:46<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "n_top = 100\n",
    "k = 20\n",
    "\n",
    "recall1, recall2, recall5, recall10, recall20 = 0,0,0,0,0\n",
    "\n",
    "for idx, qid in tqdm(enumerate(qids), total = len(qids)):\n",
    "    answer = qid_docid[qid]\n",
    "\n",
    "    cur_question = questions[qid]\n",
    "\n",
    "    cur_question_emb = question_embs[idx]\n",
    "\n",
    "    top_collection_embs = []\n",
    "\n",
    "    tokenized_question = mecab_tokenizer(cur_question)\n",
    "    doc_scores = bm25.get_scores(tokenized_question)\n",
    "\n",
    "    top_indices = np.argsort(doc_scores)[-n_top:][::-1] # 상위 n_top개 문단의 index 뽑음\n",
    "\n",
    "    for i in top_indices:\n",
    "      top_collection_embs.append(collection_embs[i])\n",
    "\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "    top_collection_embs = normalize_vectors(top_collection_embs)\n",
    "    index.add(top_collection_embs)\n",
    "\n",
    "    _, indices = index.search(cur_question_emb.reshape(1, -1), k)\n",
    "\n",
    "    for k_idx, i  in enumerate(indices[0]):\n",
    "        if doc_id[top_indices[i]] == answer:\n",
    "            if k_idx<1:\n",
    "                recall1+=1\n",
    "                recall2+=1\n",
    "                recall5+=1\n",
    "                recall10+=1\n",
    "                recall20+=1\n",
    "                break\n",
    "            elif k_idx<2:\n",
    "                recall2+=1\n",
    "                recall5+=1\n",
    "                recall10+=1\n",
    "                recall20+=1\n",
    "                break\n",
    "            elif k_idx<5:\n",
    "                recall5+=1\n",
    "                recall10+=1\n",
    "                recall20+=1\n",
    "                break\n",
    "            elif k_idx<10:\n",
    "                recall10+=1\n",
    "                recall20+=1\n",
    "                break\n",
    "            else:\n",
    "                recall20+=1\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@1 : 0.20033333333333334\n",
      "recall@2 : 0.303\n",
      "recall@5 : 0.4836666666666667\n",
      "recall@10 : 0.6263333333333333\n",
      "recall@20 : 0.7763333333333333\n"
     ]
    }
   ],
   "source": [
    "print(f'recall@1 : {recall1/len(qids)}')\n",
    "print(f'recall@2 : {recall2/len(qids)}')\n",
    "print(f'recall@5 : {recall5/len(qids)}')\n",
    "print(f'recall@10 : {recall10/len(qids)}')\n",
    "print(f'recall@20 : {recall20/len(qids)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('question_embs.npy', question_embs)\n",
    "# np.save('collection_embs.npy', collection_embs)\n",
    "\n",
    "# loaded_question_embs = np.load('question_embs.npy')\n",
    "# loaded_collection_embs = np.load('collection_embs.npy')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
